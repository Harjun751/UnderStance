{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9688c491-f4a6-4f09-8e30-fe3f182ebcfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in ./jupyter-venv/lib64/python3.12/site-packages (1.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: together in ./jupyter-venv/lib64/python3.12/site-packages (1.5.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (3.12.14)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (8.1.8)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (0.2.2)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (2.3.2)\n",
      "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (11.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (2.11.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (2.32.4)\n",
      "Requirement already satisfied: rich<15.0.0,>=13.8.1 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (14.1.0)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (4.67.1)\n",
      "Requirement already satisfied: typer<0.16,>=0.9 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (0.15.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.20.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.6.3->together) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.6.3->together) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.6.3->together) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3.0.0,>=2.31.0->together) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3.0.0,>=2.31.0->together) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3.0.0,>=2.31.0->together) (2025.7.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./jupyter-venv/lib64/python3.12/site-packages (from rich<15.0.0,>=13.8.1->together) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./jupyter-venv/lib64/python3.12/site-packages (from rich<15.0.0,>=13.8.1->together) (2.19.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./jupyter-venv/lib64/python3.12/site-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./jupyter-venv/lib64/python3.12/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.8.1->together) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain-together in ./jupyter-venv/lib64/python3.12/site-packages (0.3.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-together) (3.12.14)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-together) (0.3.72)\n",
      "Requirement already satisfied: langchain-openai<0.4,>=0.3 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-together) (0.3.28)\n",
      "Requirement already satisfied: requests<3,>=2 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-together) (2.32.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (1.20.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (2.11.7)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-openai<0.4,>=0.3->langchain-together) (1.97.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-openai<0.4,>=0.3->langchain-together) (0.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain-together) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain-together) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain-together) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain-together) (2025.7.14)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./jupyter-venv/lib64/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-together) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./jupyter-venv/lib64/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai<0.4,>=0.3->langchain-together) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./jupyter-venv/lib64/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai<0.4,>=0.3->langchain-together) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai<0.4,>=0.3->langchain-together) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./jupyter-venv/lib64/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai<0.4,>=0.3->langchain-together) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./jupyter-venv/lib64/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai<0.4,>=0.3->langchain-together) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-together) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-together) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-together) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./jupyter-venv/lib64/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai<0.4,>=0.3->langchain-together) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in ./jupyter-venv/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./jupyter-venv/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (0.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain in ./jupyter-venv/lib64/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain) (0.3.72)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in ./jupyter-venv/lib64/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: anyio in ./jupyter-venv/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./jupyter-venv/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./jupyter-venv/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./jupyter-venv/lib64/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./jupyter-venv/lib64/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain-community in ./jupyter-venv/lib64/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (0.3.72)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (3.12.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (0.4.8)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (2.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./jupyter-venv/lib64/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (25.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.1.125->langchain-community) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain-community) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in ./jupyter-venv/lib64/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
      "Requirement already satisfied: anyio in ./jupyter-venv/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./jupyter-venv/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./jupyter-venv/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./jupyter-venv/lib64/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./jupyter-venv/lib64/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./jupyter-venv/lib64/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Downloading psycopg2_binary-2.9.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.10\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install together\n",
    "!pip install langchain-together\n",
    "!pip install langchain\n",
    "!pip install langchain-community\n",
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d750c-3a2c-457d-a948-e629d16abdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8342d065-9e6c-4ad6-9a09-cadfeb8d316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79626def-3a51-4bc8-b8e0-fef4d0f84075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "import psycopg2\n",
    "API_TOKEN: Optional[str] = os.getenv(\"LLM_API_TOKEN\")\n",
    "DB_CONN_STRING: Optional[str] = os.getenv(\"DB_CONN_STRING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad38a43d-fee9-41c0-8ff9-2ec2849958a9",
   "metadata": {},
   "source": [
    "## Pydantic Classes for SDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee538153-ac1f-40b1-bdc9-d89b584312a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Deque, List, Optional, Tuple\n",
    "\n",
    "# Need to somehow cross check category\n",
    "class Issue(BaseModel):\n",
    "    \"\"\"A single issue, problem, or event that can be addressed by political parties, typically for them to form policy around.\"\"\"\n",
    "    \n",
    "    description: str = Field(description=\"\"\"\n",
    "    A long (max 300 characters) description of the issue at hand\n",
    "    It should not be tied to any political party and simply be a description of the issue discussed.\n",
    "    No details of a solution should be included, remain very general. Describe the **overarching** issue at hand.\n",
    "    it should be able to be answered with a binary agree/disagree statement. Required.\n",
    "    \"\"\")\n",
    "    summary: str = Field(description=\"A short (max 50 characters), concise, summary of the issue. again, it should not be tied to any political party and simply be a description of the issue discussed. Required.\")\n",
    "\n",
    "class Stance(BaseModel):\n",
    "    \"\"\"A political party's stance on an existing issue\"\"\"\n",
    "    \n",
    "    issue_id: int = Field(description = \"The ID of issue that is being discussed\")\n",
    "    stand: bool = Field(description = \"A boolean value indicating whether the party disagrees or agrees with the contents of the issue\")\n",
    "    reason: str = Field(description = \"A description on why the party has this stance, maximum 1000 characters\")\n",
    "    evidence: str = Field(description = \"Lines verbatim from the document that support this stance\")\n",
    "\n",
    "class StanceList(BaseModel):\n",
    "    \"\"\"A list of stances for issues that are explicitly commented on in the document. If no issues are discussed, this list should be empty.\"\"\"\n",
    "    \n",
    "    stances: Optional[List[Stance]] = Field(\n",
    "        description=\"The list of stances. Only include items if the stance is clearly and explicitly stated in the document. Do not include entries for issues not discussed.\"\n",
    "    )\n",
    "\n",
    "class IssueList(BaseModel):\n",
    "    \"A list of issues addressed in the context provided\"\n",
    "\n",
    "    issues: List[Issue]\n",
    "\n",
    "class Party(BaseModel):\n",
    "    \"A political party\"\n",
    "\n",
    "    party_id: int = Field(description = \"The exact ID of the party in question\")\n",
    "    name: str = Field(description = \"The name of the party\")\n",
    "    short_name: str = Field(description = \"The short name of the party, usually 2-3 letters long\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a67c9-e798-4a19-b6d8-b9316f9bf644",
   "metadata": {},
   "source": [
    "## Reading WP manifesto data (from .txt)\n",
    "We split the text into chunks of 6000. We use this approach because these texts are very information-dense. It is unlikely that by splitting the text, we miss data that needs to be captured. We risk duplicate items, though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a60d3dd-c4d6-4c6c-ab77-1387ae7e23ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "loader = DirectoryLoader(\"./data/\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "    # Controls the size of each chunk\n",
    "    chunk_size=5800,\n",
    "    # Controls overlap between chunks\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01000690-00be-4a51-9f58-1127e72ca1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\", model_provider=\"together\", api_key=API_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a30e8ad-f2b8-4bb4-bf4a-27d940f068e8",
   "metadata": {},
   "source": [
    "# Obtain the Party in question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f52db40-1e59-4fde-b942-9629b1405dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(DB_CONN_STRING)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('SELECT * FROM \"Party\";')\n",
    "\n",
    "# Fetch all rows\n",
    "rows = cur.fetchall()\n",
    "\n",
    "# Clean up\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e71c3f90-fdc1-4add-9497-4730983b227a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  'Coalition for Shakira',\n",
       "  'CFS',\n",
       "  'https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmedia1.tenor.com%2Fm%2FnsIzrgTUb6sAAAAC%2Fmonday-left-me-broken-cat.gif&f=1&nofb=1&ipt=037bc199f0a9705f2ffda49a41302c4a674c8d69748df626cd8e70491f1f379d',\n",
       "  '#FFD700',\n",
       "  True),\n",
       " (2,\n",
       "  \"Traditionalists' Party\",\n",
       "  'TP',\n",
       "  'https://external-content.duckduckgo.com/iu/?u=http%3A%2F%2Fpkbnews.in%2Fwp-content%2Fuploads%2F2023%2F09%2FBlue-Smurf-Cat-Meme.jpg&f=1&nofb=1&ipt=075c2e738b6abfc14555b49cfe8fe2d14433f12cdec84ab46b87516cca95278f',\n",
       "  '#1E90FF',\n",
       "  True),\n",
       " (4, 'Workers Party', 'WP', 'www.com', 'red', True)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8c10441-afed-4ec5-93d6-d9f5b7b9e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "party_data = list(map(lambda p: f\"(ID: {p[0]}, Name: {p[1]}, ShortName: {p[2]})\", rows))\n",
    "party_data = \", \".join(party_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b57d25aa-c228-448e-a7fc-e3d122b830dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Extract the correct party that the document is referring to from the predefined list of parties below\"\n",
    "        ),\n",
    "        (\"system\", \"Party List: \" + party_data),\n",
    "        # Please see the how-to about improving performance with\n",
    "        # reference examples.\n",
    "        # MessagesPlaceholder('examples'),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")\n",
    "extractor = prompt_template | model.with_structured_output(schema=Party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9b1cb60-3b12-43bd-b351-33e52e4f48b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "party_id=4 name='Workers Party' short_name='WP'\n"
     ]
    }
   ],
   "source": [
    "party = extractor.invoke(texts[0])\n",
    "print(party)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93b7db7-cc19-4c7c-9519-d80a87d86d11",
   "metadata": {},
   "source": [
    "## Create an extractor for issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac4677e4-d775-4c76-9c0f-6f15fbb4753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = model.with_structured_output(schema=IssueList)\n",
    "\n",
    "# Define a custom prompt to provide instructions and any additional context.\n",
    "# 1) You can add examples into the prompt template to improve extraction quality\n",
    "# 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
    "#    about the document from which the text was extracted.)\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Extract issues from the text, keeping the issue generalizable. Ensure that character limits are adhered to.\"\n",
    "            \"It should make sense to assign agree/disagree values to Issues.\"\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")\n",
    "extractor = prompt_template | structured_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176dd9cb-a343-4e63-8120-bb8d0504e44e",
   "metadata": {},
   "source": [
    "## Extract issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49aae098-4084-4346-bc17-367265bcdc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractions = extractor.batch(\n",
    "    [{\"text\":text} for text in texts],\n",
    "    {\"max_concurrency\":2},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d25071e9-16a4-473f-9a2e-35f4bda64656",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = []\n",
    "for extraction in extractions:\n",
    "    issues.extend(extraction.issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b45e65-1fad-4e6c-8abc-36cb7f2b4054",
   "metadata": {},
   "source": [
    "# Insert issues into database\n",
    "TODO: check before adding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d034d4ce-9e63-42f6-8370-fb33cf4573ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(DB_CONN_STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3ea30ac-a1c4-4eec-a310-61c863e4fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(map(lambda i: (i.description, i.summary), issues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d6af7f0-3d74-47f3-84f9-d994366e4006",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.executemany('INSERT INTO \"Issue\" (\"Description\", \"Summary\", \"Active\") VALUES (%s, %s, false);', data)\n",
    "\n",
    "# Clean up\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b1b0d1-2302-40f7-9c1c-396747837071",
   "metadata": {},
   "source": [
    "# GET issues from database with ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15268d16-e20b-4652-a0f9-00febb8766b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "party_id = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "352f1047-3fc5-4ca7-8e25-04b4d3d242de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above is placeholder !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ee5d79d-3832-4295-89d2-6d4f6938b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(DB_CONN_STRING)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Obtain ONLY the issues that are not answered by this party yet\n",
    "cur.execute(\"\"\"\n",
    "SELECT * FROM \"Issue\" i\n",
    "WHERE NOT EXISTS (\n",
    "    SELECT 1\n",
    "    FROM \"Stance\" s\n",
    "    WHERE i.\"IssueID\" = s.\"IssueID\"\n",
    "    AND s.\"PartyID\" = %s\n",
    ");\n",
    "\"\"\", (party_id,))\n",
    "rows = cur.fetchall()\n",
    "\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d791c3-aa2f-434a-aea2-e488c60937ec",
   "metadata": {},
   "source": [
    "## Extract stances\n",
    "\n",
    "Workflow: Get issues from database and/or from extracted values\n",
    "Use this to inform stance generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9896b4de-a970-4df6-ba5e-7472747625ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into chunks of 10 questions each\n",
    "issue_chunks = [rows[i:i + 10] for i in range(0, len(rows), 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5db71b7e-fc0d-49e0-9997-892ea9bd0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import tool_example_to_messages\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "examples = [\n",
    "    (\n",
    "        \"Singapore should ban cars in order to hit our carbon green targets by 2040\",\n",
    "        StanceList(stances=[\n",
    "            Stance(issue_id=2, stand=True, reason=\"To hit carbon green targets\", evidence=\"Singapore should ban cars in order to hit our carbon green targets by 2040\")\n",
    "        ]),\n",
    "        \"(ID: 123, Description: 'Singapore should allow cars to drift in roads')\\n(ID: 2, Description: 'Singapore should ban cars.')\"\n",
    "    ),\n",
    "    (\n",
    "        \"Singapore should deploy more soldiers overseas to assist in foreign aid efforts\",\n",
    "        StanceList(stances=[]),\n",
    "        \"(ID: 124, Description: 'Singapore should allow dogs to fly.')\\n(ID: 2, Description: 'Singapore should ban cars.')\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "messages = []\n",
    "\n",
    "for txt, tool_call, issueStr in examples:\n",
    "    if tool_call.stances:\n",
    "        # This final message is optional for some providers\n",
    "        ai_response = \"Detected a stance related to one of the provided issues, returning stance list with only 1 stance.\"\n",
    "    else:\n",
    "        ai_response = \"Detected no stances related to any of the provided Issues, returning empty stance list\"\n",
    "    example = tool_example_to_messages(txt, [tool_call], ai_response=ai_response)\n",
    "    messages.extend([HumanMessage(content=\"Example Issue List: \" + issueStr)] + example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69a1558f-4194-45bc-98db-f0b512c022ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the prompt and extractor\n",
    "from langchain.globals import set_verbose\n",
    "\n",
    "set_verbose(True)\n",
    "stance_prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                #\"system\",\n",
    "                #\"You are a strict and precise extraction algorithm.\"\n",
    "                #\"Your job is to extract a stance taken in the document if and only if:\"\n",
    "                #\"a) the stance taken directly corresponds to the description of an issue, of which the issue list will be provided\\n\"\n",
    "                #\"b) the stance is clear and explicit, and not an inference of unstated opinions or tones. **DO NOT** create a stance stating that a party does not agree just because they did not comment on a particular issue. \\n\"\n",
    "                #\"c) there is no other stance for this issue - that is, there should only be a maximum of 1 stance per issue, and a minimum of 0 stances per issue\\n\"\n",
    "                #\"Only use the issues provided below (Issue List: [....]). **DO NOT** refer to any new issues.\\n\"\n",
    "                #\"IMPORTANT: Do not return a stance for any issue that is not explicitly mentioned and discussed in the document. If the issue is not discussed, it must be left out of the result entirely. **Do not** return any stances that say 'no comment' or 'not mentioned'. These are considered invalid.\"\n",
    "                \"system\",\n",
    "                \"You are an political extraction algorithm that does not paraphrase, is neutral, and does not assume anything.\"\n",
    "                \"Your job is to extract 0 or more stances in a document if and only the stance directly corresponds to an issue with an existing ID.\"\n",
    "                \" Only refer to the **latest** issue list provided. Do not make any leap in judgements. The stance should be exactly related to the issue at hand.\"\n",
    "            ),\n",
    "            MessagesPlaceholder(\"examples\"),  # <-- EXAMPLES!\n",
    "            (\"human\", \"Issue List: [{issues}]\"),\n",
    "            (\"human\", \"{text}\"),\n",
    "        ]\n",
    "    )\n",
    "stance_extractor = stance_prompt_template | model.with_structured_output(StanceList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "126a06e8-7233-4305-97b8-a98dc76c0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over issue chunks, format them and then extract\n",
    "extracted = []\n",
    "for issue_list in issue_chunks:\n",
    "    issueStr = \"\\n\".join(f\"(ID: {i[0]}, Description: {i[1]})\" for i in issue_list)\n",
    "    # determines chunk size for input\n",
    "    # max_tokens - issues length - max return tokens - buffer\n",
    "    remainding_tokens = 8193 - len(issueStr) - 2143 - 500\n",
    "    text_splitter = TokenTextSplitter(\n",
    "        # Controls the size of each chunk\n",
    "        chunk_size=remainding_tokens,\n",
    "        # Controls overlap between chunks\n",
    "        chunk_overlap=20,\n",
    "    )\n",
    "    chunked_text = text_splitter.split_text(docs[0].page_content)\n",
    "    for text in chunked_text:\n",
    "        extractions = stance_extractor.invoke({\"text\": text, \"issues\": issueStr, \"examples\": messages})\n",
    "        extracted.extend(extractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d68972-7ae0-43ab-a09c-dad2e0c43fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407cf00f-4359-4f1f-b8a8-4a2fc0a2004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda x: x[0] == 138, rows))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
