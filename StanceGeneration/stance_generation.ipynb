{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9688c491-f4a6-4f09-8e30-fe3f182ebcfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in ./jupyter-venv/lib64/python3.12/site-packages (1.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: together in ./jupyter-venv/lib64/python3.12/site-packages (1.5.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (3.12.14)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (8.1.8)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (0.2.2)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (2.3.2)\n",
      "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (11.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (2.11.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (2.32.4)\n",
      "Requirement already satisfied: rich<15.0.0,>=13.8.1 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (14.1.0)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (4.67.1)\n",
      "Requirement already satisfied: typer<0.16,>=0.9 in ./jupyter-venv/lib64/python3.12/site-packages (from together) (0.15.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.20.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.6.3->together) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.6.3->together) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.6.3->together) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3.0.0,>=2.31.0->together) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3.0.0,>=2.31.0->together) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3.0.0,>=2.31.0->together) (2025.7.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./jupyter-venv/lib64/python3.12/site-packages (from rich<15.0.0,>=13.8.1->together) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./jupyter-venv/lib64/python3.12/site-packages (from rich<15.0.0,>=13.8.1->together) (2.19.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./jupyter-venv/lib64/python3.12/site-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./jupyter-venv/lib64/python3.12/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.8.1->together) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain-together in ./jupyter-venv/lib64/python3.12/site-packages (0.3.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-together) (3.12.14)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-together) (0.3.72)\n",
      "Requirement already satisfied: langchain-openai<0.4,>=0.3 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-together) (0.3.28)\n",
      "Requirement already satisfied: requests<3,>=2 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-together) (2.32.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (1.20.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-together) (2.11.7)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-openai<0.4,>=0.3->langchain-together) (1.97.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-openai<0.4,>=0.3->langchain-together) (0.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain-together) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain-together) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain-together) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain-together) (2025.7.14)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./jupyter-venv/lib64/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-together) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./jupyter-venv/lib64/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai<0.4,>=0.3->langchain-together) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./jupyter-venv/lib64/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai<0.4,>=0.3->langchain-together) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai<0.4,>=0.3->langchain-together) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./jupyter-venv/lib64/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai<0.4,>=0.3->langchain-together) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./jupyter-venv/lib64/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai<0.4,>=0.3->langchain-together) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-together) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-together) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-together) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./jupyter-venv/lib64/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai<0.4,>=0.3->langchain-together) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in ./jupyter-venv/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./jupyter-venv/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain-together) (0.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain in ./jupyter-venv/lib64/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain) (0.3.72)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in ./jupyter-venv/lib64/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: anyio in ./jupyter-venv/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./jupyter-venv/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./jupyter-venv/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./jupyter-venv/lib64/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./jupyter-venv/lib64/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain-community in ./jupyter-venv/lib64/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (0.3.72)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (3.12.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (0.4.8)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-community) (2.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./jupyter-venv/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./jupyter-venv/lib64/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in ./jupyter-venv/lib64/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (25.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.1.125->langchain-community) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./jupyter-venv/lib64/python3.12/site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./jupyter-venv/lib64/python3.12/site-packages (from requests<3,>=2->langchain-community) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in ./jupyter-venv/lib64/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
      "Requirement already satisfied: anyio in ./jupyter-venv/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./jupyter-venv/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./jupyter-venv/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./jupyter-venv/lib64/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./jupyter-venv/lib64/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./jupyter-venv/lib64/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./jupyter-venv/lib64/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Downloading psycopg2_binary-2.9.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.10\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install together\n",
    "!pip install langchain-together\n",
    "!pip install langchain\n",
    "!pip install langchain-community\n",
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d750c-3a2c-457d-a948-e629d16abdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8342d065-9e6c-4ad6-9a09-cadfeb8d316a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79626def-3a51-4bc8-b8e0-fef4d0f84075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "import psycopg2\n",
    "API_TOKEN: Optional[str] = os.getenv(\"LLM_API_TOKEN\")\n",
    "DB_CONN_STRING: Optional[str] = os.getenv(\"DB_CONN_STRING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8a0e8c-fb80-4366-a6ea-1d3121ec5895",
   "metadata": {},
   "source": [
    "# DELETE THIS!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ea0a945-44ec-4189-a29a-6b9fe6298aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_CONN_STRING = \"postgresql://user:cellsinterlinked@localhost:5432/UnderStance\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad38a43d-fee9-41c0-8ff9-2ec2849958a9",
   "metadata": {},
   "source": [
    "## Pydantic Classes for SDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ee538153-ac1f-40b1-bdc9-d89b584312a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Deque, List, Optional, Tuple\n",
    "\n",
    "# Need to somehow cross check category\n",
    "class Issue(BaseModel):\n",
    "    \"\"\"A single issue, problem, or event that can be addressed by political parties, typically for them to form policy around.\"\"\"\n",
    "    \n",
    "    description: str = Field(description=\"\"\"\n",
    "    A long (max 300 characters) description of the issue at hand\n",
    "    It should not be tied to any political party and simply be a description of the issue discussed.\n",
    "    No details of a solution should be included, remain very general. Describe the **overarching** issue at hand.\n",
    "    it should be able to be answered with a binary agree/disagree statement. Required.\n",
    "    \"\"\")\n",
    "    summary: str = Field(description=\"A short (max 50 characters), concise, summary of the issue. again, it should not be tied to any political party and simply be a description of the issue discussed. Required.\")\n",
    "\n",
    "class Stance(BaseModel):\n",
    "    \"\"\"A political party's stance on an issue\"\"\"\n",
    "    \n",
    "    issue_id: int = Field(description = \"The ID of issue that is being discussed\")\n",
    "    stand: bool = Field(description = \"Whether the party disagrees or agrees with the contents of the issue\")\n",
    "    reason: str = Field(description = \"A description on why the party has this stance, maximum 1000 characters\")\n",
    "    evidence: str = Field(description = \"Lines verbatim from the document that support this stance\")\n",
    "\n",
    "class StanceList(BaseModel):\n",
    "    stances: Optional[List[Stance]] = Field(\n",
    "        default=[], description=\"The list of stances\"\n",
    "    )\n",
    "\n",
    "class IssueList(BaseModel):\n",
    "    \"A list of issues addressed in the context provided\"\n",
    "\n",
    "    issues: List[Issue]\n",
    "\n",
    "class Party(BaseModel):\n",
    "    \"A political party\"\n",
    "\n",
    "    party_id: int = Field(description = \"The exact ID of the party in question\")\n",
    "    name: str = Field(description = \"The name of the party\")\n",
    "    short_name: str = Field(description = \"The short name of the party, usually 2-3 letters long\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a67c9-e798-4a19-b6d8-b9316f9bf644",
   "metadata": {},
   "source": [
    "## Reading WP manifesto data (from .txt)\n",
    "We split the text into chunks of 6000. We use this approach because these texts are very information-dense. It is unlikely that by splitting the text, we miss data that needs to be captured. We risk duplicate items, though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a60d3dd-c4d6-4c6c-ab77-1387ae7e23ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "loader = DirectoryLoader(\"./data/\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "    # Controls the size of each chunk\n",
    "    chunk_size=5800,\n",
    "    # Controls overlap between chunks\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01000690-00be-4a51-9f58-1127e72ca1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\", model_provider=\"together\", api_key=API_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a30e8ad-f2b8-4bb4-bf4a-27d940f068e8",
   "metadata": {},
   "source": [
    "# Obtain the Party in question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8f52db40-1e59-4fde-b942-9629b1405dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(DB_CONN_STRING)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('SELECT * FROM \"Party\";')\n",
    "\n",
    "# Fetch all rows\n",
    "rows = cur.fetchall()\n",
    "\n",
    "# Clean up\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e71c3f90-fdc1-4add-9497-4730983b227a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  'Coalition for Shakira',\n",
       "  'CFS',\n",
       "  'https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmedia1.tenor.com%2Fm%2FnsIzrgTUb6sAAAAC%2Fmonday-left-me-broken-cat.gif&f=1&nofb=1&ipt=037bc199f0a9705f2ffda49a41302c4a674c8d69748df626cd8e70491f1f379d',\n",
       "  '#FFD700',\n",
       "  True),\n",
       " (2,\n",
       "  \"Traditionalists' Party\",\n",
       "  'TP',\n",
       "  'https://external-content.duckduckgo.com/iu/?u=http%3A%2F%2Fpkbnews.in%2Fwp-content%2Fuploads%2F2023%2F09%2FBlue-Smurf-Cat-Meme.jpg&f=1&nofb=1&ipt=075c2e738b6abfc14555b49cfe8fe2d14433f12cdec84ab46b87516cca95278f',\n",
       "  '#1E90FF',\n",
       "  True),\n",
       " (4, 'Workers Party', 'WP', 'www.com', 'red', True)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c8c10441-afed-4ec5-93d6-d9f5b7b9e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "party_data = list(map(lambda p: f\"(ID: {p[0]}, Name: {p[1]}, ShortName: {p[2]})\", rows))\n",
    "party_data = \", \".join(party_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b57d25aa-c228-448e-a7fc-e3d122b830dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Extract the correct party that the document is referring to from the predefined list of parties below\"\n",
    "        ),\n",
    "        (\"system\", \"Party List: \" + party_data),\n",
    "        # Please see the how-to about improving performance with\n",
    "        # reference examples.\n",
    "        # MessagesPlaceholder('examples'),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")\n",
    "extractor = prompt_template | model.with_structured_output(schema=Party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a9b1cb60-3b12-43bd-b351-33e52e4f48b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "party_id=4 name='Workers Party' short_name='WP'\n"
     ]
    }
   ],
   "source": [
    "party = extractor.invoke(texts[0])\n",
    "print(party)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93b7db7-cc19-4c7c-9519-d80a87d86d11",
   "metadata": {},
   "source": [
    "## Create an extractor for issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ac4677e4-d775-4c76-9c0f-6f15fbb4753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = model.with_structured_output(schema=IssueList)\n",
    "\n",
    "# Define a custom prompt to provide instructions and any additional context.\n",
    "# 1) You can add examples into the prompt template to improve extraction quality\n",
    "# 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
    "#    about the document from which the text was extracted.)\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Only extract relevant information from the text. \"\n",
    "            \"If you do not know the value of an attribute asked to extract, \"\n",
    "            \"return null for the attribute's value.\",\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")\n",
    "extractor = prompt_template | structured_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176dd9cb-a343-4e63-8120-bb8d0504e44e",
   "metadata": {},
   "source": [
    "## Extract issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5e45d12f-7d89-4a34-8e8f-126059c01eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex = [Issue(description=\"Singapore should improve MRT infrastructure\", summary=\"Improving MRTs\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "49aae098-4084-4346-bc17-367265bcdc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractions = extractor.batch(\n",
    "    [{\"text\":text} for text in texts],\n",
    "    {\"max_concurrency\":2},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d25071e9-16a4-473f-9a2e-35f4bda64656",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = []\n",
    "for extraction in extractions:\n",
    "    issues.extend(extraction.issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b45e65-1fad-4e6c-8abc-36cb7f2b4054",
   "metadata": {},
   "source": [
    "# Insert issues into database\n",
    "TODO: check before adding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d034d4ce-9e63-42f6-8370-fb33cf4573ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(DB_CONN_STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3ea30ac-a1c4-4eec-a310-61c863e4fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(map(lambda i: (i.description, i.summary), issues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d6af7f0-3d74-47f3-84f9-d994366e4006",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.executemany('INSERT INTO \"Issue\" (\"Description\", \"Summary\", \"Acti) VALUES (%s, %s);', data)\n",
    "\n",
    "# Clean up\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b1b0d1-2302-40f7-9c1c-396747837071",
   "metadata": {},
   "source": [
    "# GET issues from database with ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "15268d16-e20b-4652-a0f9-00febb8766b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "party.party_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3ee5d79d-3832-4295-89d2-6d4f6938b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(DB_CONN_STRING)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Obtain ONLY the issues that are not answered by this party yet\n",
    "cur.execute(\"\"\"\n",
    "SELECT * FROM \"Issue\" i\n",
    "WHERE NOT EXISTS (\n",
    "    SELECT 1\n",
    "    FROM \"Stance\" s\n",
    "    WHERE i.\"IssueID\" = s.\"IssueID\"\n",
    "    AND s.\"PartyID\" = %s\n",
    ");\n",
    "\"\"\", (party.party_id,))\n",
    "rows = cur.fetchall()\n",
    "\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d791c3-aa2f-434a-aea2-e488c60937ec",
   "metadata": {},
   "source": [
    "## Extract stances\n",
    "\n",
    "Workflow: Get issues from database and/or from extracted values\n",
    "Use this to inform stance generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9896b4de-a970-4df6-ba5e-7472747625ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into chunks of 10 questions each\n",
    "issue_chunks = [rows[i:i + 10] for i in range(0, len(rows), 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5db71b7e-fc0d-49e0-9997-892ea9bd0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import tool_example_to_messages\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "examples = [\n",
    "    (\n",
    "        \"This is an example document that provides a clear stance on the issue with id 123\",\n",
    "        StanceList(stances=[\n",
    "            Stance(issue_id=123, stand=True, reason=\"placeholder example reason\", evidence=\"This is an example document that provides a clear stance on the issue with id 123\")\n",
    "        ]),\n",
    "        \"{'ID': 123, 'Description': 'Example issue'}, {'ID': 2, 'Description': 'Singapore should ban cars.'}\"\n",
    "    ),\n",
    "    (\n",
    "        \"Fiona traveled far from France to Spain.\",\n",
    "        StanceList(stances=[]),\n",
    "        \"{'ID': 124, 'Description': 'Singapore should recognise the State of Palestine'}, {'ID': 2, 'Description': 'Singapore should ban cars.'}\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "messages = []\n",
    "\n",
    "for txt, tool_call, issueStr in examples:\n",
    "    if tool_call.stances:\n",
    "        # This final message is optional for some providers\n",
    "        ai_response = \"Detected stances.\"\n",
    "    else:\n",
    "        ai_response = \"Detected no stances.\"\n",
    "    example = tool_example_to_messages(txt, [tool_call], ai_response=ai_response)\n",
    "    messages.extend([SystemMessage(content=\"Issue List: \" + issueStr)] + example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "69a1558f-4194-45bc-98db-f0b512c022ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the prompt and extractor\n",
    "stance_prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"You are a strict and precise extraction algorithm.\"\n",
    "                \"Your job is to extract a stance taken in the document if and only if:\"\n",
    "                \"a) the stance taken directly corresponds to the description of an issue, of which the issue list will be provided\"\n",
    "                \"b) the stance is clear and explicit, and not an inference of unstated opinions or tones\"\n",
    "                \"c) there is no other stance for this issue - that is, there should only be a maximum of 1 stance per issue, and a minimum of 0 stances per issue\"\n",
    "            ),\n",
    "            (\"system\", \"Issue List: {issues}\"),\n",
    "            MessagesPlaceholder(\"examples\"),  # <-- EXAMPLES!\n",
    "            (\"human\", \"{text}\"),\n",
    "        ]\n",
    "    )\n",
    "stance_extractor = stance_prompt_template | model.with_structured_output(StanceList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "126a06e8-7233-4305-97b8-a98dc76c0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over issue chunks, format them and then extract\n",
    "extracted = []\n",
    "for issue_list in issue_chunks:\n",
    "    issueStr = \"\\n\".join(f\"(ID: {i[0]}, Description: {i[1]})\" for i in issue_list)\n",
    "    # determines chunk size for input\n",
    "    # max_tokens - issues length - max return tokens - buffer\n",
    "    remainding_tokens = 8193 - len(issueStr) - 2143 - 500\n",
    "    text_splitter = TokenTextSplitter(\n",
    "        # Controls the size of each chunk\n",
    "        chunk_size=remainding_tokens,\n",
    "        # Controls overlap between chunks\n",
    "        chunk_overlap=20,\n",
    "    )\n",
    "    chunked_text = text_splitter.split_text(docs[0].page_content)\n",
    "    for text in chunked_text:\n",
    "        extractions = stance_extractor.invoke({\"text\": text, \"issues\": issueStr, \"examples\": messages})\n",
    "        extracted.extend(extractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2bbd6d54-ca91-4a10-97c6-ee778cea6f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stances',\n",
       "  [Stance(issue_id=1, stand=False, reason=\"The Workers' Party does not support changing the national anthem to 'hips don't lie'.\", evidence='No evidence of support for changing the national anthem.'),\n",
       "   Stance(issue_id=2, stand=False, reason=\"The Workers' Party does not support mandating weekly rhythm & dance classes for MPs.\", evidence='No evidence of support for mandating dance classes for MPs.'),\n",
       "   Stance(issue_id=3, stand=False, reason=\"The Workers' Party does not support renaming the National Day Rally to 'Shake it Summit'.\", evidence='No evidence of support for renaming the National Day Rally.'),\n",
       "   Stance(issue_id=4, stand=False, reason=\"The Workers' Party does not support tax breaks for streaming Shakira's hits.\", evidence=\"No evidence of support for tax breaks for streaming Shakira's hits.\"),\n",
       "   Stance(issue_id=5, stand=True, reason=\"The Workers' Party supports banning lying in politics.\", evidence=\"The Workers' Party has proposed policies to increase transparency and accountability in government.\"),\n",
       "   Stance(issue_id=6, stand=False, reason=\"The Workers' Party does not support using interpretive dance to explain the national budget.\", evidence='No evidence of support for using interpretive dance to explain the national budget.'),\n",
       "   Stance(issue_id=7, stand=False, reason=\"The Workers' Party does not support replacing the Ministry of Culture with the Ministry of Groove.\", evidence='No evidence of support for replacing the Ministry of Culture.'),\n",
       "   Stance(issue_id=8, stand=False, reason=\"The Workers' Party does not support including salsa dance in national service training.\", evidence='No evidence of support for including salsa dance in national service training.'),\n",
       "   Stance(issue_id=9, stand=False, reason=\"The Workers' Party does not support declaring Shakira's birthday a national holiday.\", evidence=\"No evidence of support for declaring Shakira's birthday a national holiday.\"),\n",
       "   Stance(issue_id=10, stand=False, reason=\"The Workers' Party does not support installing a dance floor in Parliament.\", evidence='No evidence of support for installing a dance floor in Parliament.')]),\n",
       " ('stances',\n",
       "  [Stance(issue_id=124, stand=True, reason='The WP believes that Singapore should recognise the State of Palestine.', evidence='The WP proposes that Singapore should recognise the State of Palestine.'),\n",
       "   Stance(issue_id=2, stand=True, reason='The WP believes that Singapore should ban cars.', evidence='The WP proposes that Singapore should ban cars.')]),\n",
       " ('stances',\n",
       "  [Stance(issue_id=124, stand=True, reason='Singapore should recognise the State of Palestine as it is a matter of international law and human rights', evidence='The international community has consistently recognised the right of the Palestinian people to self-determination and statehood'),\n",
       "   Stance(issue_id=2, stand=False, reason=\"Banning cars in Singapore is not a feasible solution as it would cause significant disruptions to the economy and people's lives\", evidence='Singapore has a well-developed public transportation system, and banning cars would not be an effective way to reduce congestion or pollution')]),\n",
       " ('stances',\n",
       "  [Stance(issue_id=1, stand=True, reason='The current education system forces children to face their first major examination when they are just 12 years old, which can lead to test anxiety and poorer performance.', evidence='Our education system forces children to face their first major examination when they are just 12 years old. Test anxiety is likely to be greater for young children, and can lead to poorer performance during exams.'),\n",
       "   Stance(issue_id=2, stand=True, reason='The high costs of private tuition widens the gap between children from different income groups.', evidence='The high costs of private tuition widens the gap between children from different income groups. Subsidised tuition programmes currently in place do not plug the gap and remain inaccessible to many vulnerable families.'),\n",
       "   Stance(issue_id=3, stand=True, reason='PwDs face barriers in accessing SkillsFuture-funded courses, mainly due to most training providers’ lack of accommodations tailored to their physical and learning needs.', evidence='PwDs face barriers in accessing SkillsFuture-funded courses, mainly due to most training providers’ lack of accommodations tailored to their physical and learning needs.'),\n",
       "   Stance(issue_id=4, stand=True, reason='An increasing number of Singaporeans marry foreigners, with one in four having a foreign spouse.', evidence='An increasing number of Singaporeans marry foreigners, with one in four having a foreign spouse.'),\n",
       "   Stance(issue_id=5, stand=True, reason='The Immigration and Customs Authority (ICA) should publish and utilise a structured, points-based system that outlines the residency criteria for foreign spouses.', evidence='The Immigration and Customs Authority (ICA) should publish and utilise a structured, points-based system that outlines the residency criteria for foreign spouses.'),\n",
       "   Stance(issue_id=6, stand=True, reason='Currently, when residency applications are rejected by ICA, no reasons are provided.', evidence='Currently, when residency applications are rejected by ICA, no reasons are provided.'),\n",
       "   Stance(issue_id=7, stand=True, reason='Over 80 per cent of Singapore residents reside in HDB public housing.', evidence='Over 80 per cent of Singapore residents reside in HDB public housing.'),\n",
       "   Stance(issue_id=8, stand=True, reason='Single Singaporeans currently have to wait until they are aged 35 to apply for a 2-room BTO flat.', evidence='Single Singaporeans currently have to wait until they are aged 35 to apply for a 2-room BTO flat.'),\n",
       "   Stance(issue_id=9, stand=True, reason='The Ethnic Integration Policy (EIP) was introduced in 1989, to maintain the ethnic balance within HDB estates.', evidence='The Ethnic Integration Policy (EIP) was introduced in 1989, to maintain the ethnic balance within HDB estates.'),\n",
       "   Stance(issue_id=10, stand=True, reason='Singapore’s tight labour market could benefit from continual efforts to lower barriers to entry.', evidence='Singapore’s tight labour market could benefit from continual efforts to lower barriers to entry.'),\n",
       "   Stance(issue_id=11, stand=True, reason='A gender pay gap of around 6 per cent persists in Singapore, even after adjusting for differences in age, education, occupation, industry and usual hours worked.', evidence='A gender pay gap of around 6 per cent persists in Singapore, even after adjusting for differences in age, education, occupation, industry and usual hours worked.'),\n",
       "   Stance(issue_id=12, stand=True, reason='Non-compete clauses should be banned in employment contracts for mid-level and low-level employees.', evidence='Non-compete clauses should be banned in employment contracts for mid-level and low-level employees.'),\n",
       "   Stance(issue_id=13, stand=True, reason='PwDs working in Singapore currently lack sufficient legal protection against discrimination, particularly in employment.', evidence='PwDs working in Singapore currently lack sufficient legal protection against discrimination, particularly in employment.'),\n",
       "   Stance(issue_id=14, stand=True, reason='The government’s adjustments to the Working Mother’s Child Relief (WMCR) with effect from Year of Assessment 2025 to a fixed dollar tax relief leaves a large majority of working mothers either unaffected or worse off.', evidence='The government’s adjustments to the Working Mother’s Child Relief (WMCR) with effect from Year of Assessment 2025 to a fixed dollar tax relief leaves a large majority of working mothers either unaffected or worse off.'),\n",
       "   Stance(issue_id=15, stand=True, reason='Thaipusam is a spiritually significant and joyous affair for Hindus in Singapore.', evidence='Thaipusam is a spiritually significant and joyous affair for Hindus in Singapore.'),\n",
       "   Stance(issue_id=16, stand=True, reason='Local sports coverage is often limited.', evidence='Local sports coverage is often limited.'),\n",
       "   Stance(issue_id=17, stand=True, reason='World-class athletes are not made through talent alone.', evidence='World-class athletes are not made through talent alone.'),\n",
       "   Stance(issue_id=18, stand=True, reason='National athletes often face health issues related to their sporting activities, sometimes with inadequate support for the treatment of sports injuries.', evidence='National athletes often face health issues related to their sporting activities, sometimes with inadequate support for the treatment of sports injuries.'),\n",
       "   Stance(issue_id=19, stand=True, reason='Accountability in a democracy goes beyond the holding of elections every few years to choose elected officials.', evidence='Accountability in a democracy goes beyond the holding of elections every few years to choose elected officials.'),\n",
       "   Stance(issue_id=20, stand=True, reason='The existing appeals system to government agencies and ministries routes appeals back to the same bureaucracy that decided on the original case.', evidence='The existing appeals system to government agencies and ministries routes appeals back to the same bureaucracy that decided on the original case.'),\n",
       "   Stance(issue_id=21, stand=True, reason='Parliamentary Select Committees are not currently tied to the functional ministries.', evidence='Parliamentary Select Committees are not currently tied to the functional ministries.'),\n",
       "   Stance(issue_id=22, stand=True, reason='A Parliamentary Budget Office can improve fiscal performance in Singapore by providing non-partisan assessments of major policy proposals.', evidence='A Parliamentary Budget Office can improve fiscal performance in Singapore by providing non-partisan assessments of major policy proposals.'),\n",
       "   Stance(issue_id=23, stand=True, reason='The Presidential Council for Minority Rights (PCMR) was formed in 1970 to scrutinise bills passed by Parliament for any differentiating measures that discriminate against any racial or religious community.', evidence='The Presidential Council for Minority Rights (PCMR) was formed in 1970 to scrutinise bills passed by Parliament for any differentiating measures that discriminate against any racial or religious community.'),\n",
       "   Stance(issue_id=24, stand=True, reason='The Ministerial Code of Conduct should set out clearly the circumstances under which a minister should recuse themselves from decision-making.', evidence='The Ministerial Code of Conduct should set out clearly the circumstances under which a minister should recuse themselves from decision-making.'),\n",
       "   Stance(issue_id=25, stand=True, reason='Lobbying is a common practice in market driven societies.', evidence='Lobbying is a common practice in market driven societies.'),\n",
       "   Stance(issue_id=26, stand=True, reason='Voters choose their representatives to speak for them in Parliament, and it is through their MPs that the people express their voice.', evidence='Voters choose their representatives to speak for them in Parliament, and it is through their MPs that the people express their voice.'),\n",
       "   Stance(issue_id=27, stand=True, reason='Singapore is currently only one of eight countries with a minimum voting age of 21 or older.', evidence='Singapore is currently only one of eight countries with a minimum voting age of 21 or older.'),\n",
       "   Stance(issue_id=28, stand=True, reason='National institutions should be independent in theory and practice, and crucially also be seen to be so.', evidence='National')]),\n",
       " ('stances',\n",
       "  [Stance(issue_id=124, stand=True, reason='Singapore should recognise the State of Palestine as it is a matter of international law and human rights', evidence='The United Nations has recognized Palestine as a non-member observer state since 2012'),\n",
       "   Stance(issue_id=2, stand=True, reason='Singapore should ban cars to reduce carbon emissions and promote a more sustainable environment', evidence=\"According to the National Environment Agency, the transportation sector accounts for 15% of Singapore's total carbon emissions\")]),\n",
       " ('stances',\n",
       "  [Stance(issue_id=124, stand=True, reason='Many Singaporeans care deeply about the pain and suffering of the people in these lands, and wish to see a peaceful resolution to the conflict.', evidence='We support a negotiated two-state solution where two democratic states, Israel and Palestine, live in peace within secure and recognised borders.'),\n",
       "   Stance(issue_id=2, stand=False, reason='No clear stance on banning cars in Singapore', evidence='No mention of banning cars in Singapore')])]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ca1107f-346e-482c-8552-f4fce5b6ca98",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
